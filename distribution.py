# dist_app.py â€“ Streamlit app to identify the bestâ€‘fitting distribution for pasted or uploaded data
# ---------------------------------------------------------------------------------------------
# VersiÃ³n extendida: incluye distribuciÃ³n piramidal (triangular) y otras distribuciones comunes
# + NUEVO: menÃº interactivo de **opciones GLM** para cada distribuciÃ³n ganadora
# ---------------------------------------------------------------------------------------------
# EjecuciÃ³n local
#   pip install streamlit pandas numpy scipy matplotlib
#   streamlit run dist_app.py
# ---------------------------------------------------------------------------------------------

from typing import List, Dict

import numpy as np
import pandas as pd
import scipy.stats as stats
import streamlit as st
import matplotlib.pyplot as plt

st.set_page_config(page_title="Detector de distribuciones", layout="centered")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Diccionarios auxiliares
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

DIST_FULL_NAMES = {
    "norm": "Normal (Gaussiana)",
    "expon": "Exponencial",
    "gamma": "Gamma",
    "lognorm": "Logâ€‘normal",
    "weibull_min": "Weibull (mÃ­nimo)",
    "beta": "Beta",
    "poisson": "Poisson",
    "triang": "Triangular (Piramidal)",
    "uniform": "Uniforme",
    "nbinom": "Binomial negativa",
    "geom": "GeomÃ©trica",
    "pareto": "Pareto",
}

# GLM sugerido por defecto (mostrar en tabla y encabezado)
REG_RECOMMENDED = {
    "norm": "GLM Gaussian (identidad)",
    "expon": "GLM Exponencial (log)",
    "gamma": "GLM Gamma (log)",
    "lognorm": "GLM Gaussian sobre log(Y)",
    "weibull_min": "Modelo Weibull AFT",
    "beta": "RegresiÃ³n Beta (logit)",
    "poisson": "GLM Poisson (log)",
    "triang": "MÃ­nimos cuadrados triangular",
    "uniform": "Modelo no paramÃ©trico",
    "nbinom": "GLM Binomial Negativa (log)",
    "geom": "RegresiÃ³n GeomÃ©trica",
    "pareto": "Modelo Pareto POT (log)",
}

# NUEVO: listado de opciones GLM detalladas por distribuciÃ³n
GLM_OPTIONS = {
    "norm": [
        "GLM Gaussian (identidad)",
        "GLM Gaussian (inverse) â€” varianza âˆ Î¼Â²",
        "GLM Gaussian (log)"
    ],
    "expon": [
        "GLM Exponencial (log)",
        "GLM Exponencial (identity)"
    ],
    "gamma": [
        "GLM Gamma (log)",
        "GLM Gamma (inverse)",
        "GLM Gamma (identity)"
    ],
    "beta": [
        "RegresiÃ³n Beta (logit)",
        "RegresiÃ³n Beta (probit)",
        "RegresiÃ³n Beta (cloglog)"
    ],
    "poisson": [
        "GLM Poisson (log)",
        "GLM Poisson (sqrt)",
        "GLM Quasiâ€‘Poisson (log) â€” sobredispersiÃ³n"
    ],
    "nbinom": [
        "GLM NB (log)",
        "GLM NB (identity)"
    ],
    "weibull_min": [
        "Modelo AFT Weibull",
        "Modelo de riesgos proporcionales Weibull"
    ],
    "triang": ["No estÃ¡ndar â€” mÃ­nimos cuadrados"],
    "uniform": ["No estÃ¡ndar"],
    "geom": ["RegresiÃ³n GeomÃ©trica (log)"]
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Funciones auxiliares
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def parse_text_input(text: str) -> np.ndarray:
    if not text:
        return np.array([])
    for sep in (",", "\n", "\t", ";"):
        text = text.replace(sep, " ")
    tokens = [t for t in text.strip().split() if t]
    vals = []
    for tk in tokens:
        try:
            vals.append(float(tk))
        except ValueError:
            continue
    return np.array(vals, dtype=float)


def get_candidate_distributions(data: np.ndarray) -> List[str]:
    cand = ["norm"]
    if np.all(data >= 0):
        cand += ["expon", "gamma", "lognorm", "weibull_min", "triang", "uniform", "pareto"]
    if np.all((0 <= data) & (data <= 1)):
        cand.append("beta")
    if np.all(np.mod(data, 1) == 0):
        cand += ["poisson", "nbinom", "geom"]
    seen, ordered = set(), []
    for d in cand:
        if d not in seen:
            seen.add(d)
            ordered.append(d)
    return ordered


def fit_distribution(dist_name: str, data: np.ndarray) -> Dict[str, object]:
    n = len(data)
    if dist_name == "poisson":
        lam = data.mean()
        loglik = np.sum(stats.poisson.logpmf(data, lam))
        params, k = (lam,), 1
    elif dist_name == "nbinom":
        mean, var = data.mean(), data.var()
        p0 = mean / var if var > mean else 0.5
        r0 = mean * p0 / (1 - p0) if p0 < 1 else 1
        dist = stats.nbinom
        params = dist.fit(data, r0, p0)
        loglik = np.sum(dist.logpmf(data, *params))
        k = len(params)
    else:
        dist = getattr(stats, dist_name)
        params = dist.fit(data)
        try:
            loglik = np.sum(dist.logpdf(data, *params))
        except Exception:
            loglik = -np.inf
        k = len(params)
    aic = 2 * k - 2 * loglik
    bic = k * np.log(n) - 2 * loglik
    return {"distribution": dist_name, "params": params, "loglik": loglik, "aic": aic, "bic": bic}


def summarize_results(res):
    return pd.DataFrame(res).sort_values("aic").reset_index(drop=True)


def show_aic_plot(df):
    fig, ax = plt.subplots()
    ax.bar(df["distribution"], df["aic"])
    ax.set_ylabel("AIC (menor es mejor)")
    ax.set_xlabel("DistribuciÃ³n")
    ax.set_title("ComparaciÃ³n de AIC entre distribuciones candidatas")
    plt.xticks(rotation=45, ha="right")
    st.pyplot(fig)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Interfaz
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.title("ðŸ” Detector automÃ¡tico de distribuciones + opciones GLM")

st.markdown("Pegue sus datos o cargue un **CSV/Excel** y obtenga la mejor distribuciÃ³n junto con un menÃº de **modelos GLM** disponibles.")

st.sidebar.header("âš™ï¸ Opciones")
alpha = st.sidebar.slider("Nivel de significancia KS", 0.01, 0.20, 0.05, 0.01)

method = st.radio("MÃ©todo de entrada", ["Pegar texto", "Subir archivo"])
if method == "Pegar texto":
    raw = st.text_area("Pegue los valores numÃ©ricos")
    data = parse_text_input(raw)
else:
    file = st.file_uploader("Archivo .csv o .xlsx", type=["csv", "xlsx"])
    if file is not None:
        try:
            df_up = pd.read_csv(file) if file.name.endswith(".csv") else pd.read_excel(file)
            num_cols = df_up.select_dtypes(include=[np.number]).columns.tolist()
            if num_cols:
                col = st.selectbox("Columna a analizar", num_cols)
                data = df_up[col].dropna().to_numpy()
            else:
                st.error("No hay columnas numÃ©ricas.")
                data = np.array([])
        except Exception as e:
            st.error(f"Error leyendo archivo: {e}")
            data = np.array([])
    else:
        data = np.array([])

if data.size == 0:
    st.info("Ingrese datos para continuar.")
    st.stop()
if data.size < 8:
    st.warning("Se recomienda n â‰¥ 8 para robustez.")

st.write(f"**Observaciones vÃ¡lidas:** {data.size}")

cands = get_candidate_distributions(data)
st.write("Distribuciones candidatas:", ", ".join(cands))

results = []
for d in cands:
    try:
        results.append(fit_distribution(d, data))
    except Exception as err:
        st.warning(f"{d}: error en ajuste â†’ {err}")

if not results:
    st.error("No se pudo ajustar ninguna distribuciÃ³n.")
    st.stop()

summary = summarize_results(results)

best = summary.iloc[0]

st.subheader("ðŸ† Mejor distribuciÃ³n (AIC minimo)")
st.markdown(
    f"**{DIST_FULL_NAMES.get(best['distribution'], best['distribution']).upper()}**  \
    ParÃ¡metros: {np.round(best['params'], 4).tolist()}  \
    AIC = {best['aic']:.2f} | BIC = {best['bic']:.2f}  \
    **RegresiÃ³n sugerida:** {REG_RECOMMENDED.get(best['distribution'], 'No disponible')}"
)

# Tabla completa
st.subheader("Tabla completa de resultados")
summary_disp = summary.copy()
summary_disp["DistribuciÃ³n completa"] = summary_disp["distribution"].map(DIST_FULL_NAMES)
summary_disp["RegresiÃ³n recomendada"] = summary_disp["distribution"].map(REG_RECOMMENDED)

st.dataframe(
    summary_disp[[
        "distribution",
        "DistribuciÃ³n completa",
        "aic",
        "bic",
        "RegresiÃ³n recomendada",
        "params",
    ]]
)

# GrÃ¡fico AIC
st.subheader("GrÃ¡fico de comparaciÃ³n de AIC")
show_aic_plot(summary)

# KS para la mejor distribuciÃ³n
st.subheader("ðŸ“Š Prueba de bondad de ajuste KS")
try:
    if best["distribution"] == "poisson":
        lam = best["params"][0]
        D, p = stats.kstest(data, "poisson", args=(lam,))
    else:
        D, p = stats.kstest(data, best["distribution"], args=best["params"])
    st.write(f"D = {D:.3f}, p = {p:.4f}")
    if p < alpha:
        st.warning("Se rechaza H0: la distribuciÃ³n podrÃ­a no ajustar bien.")
    else:
        st.success("No se rechaza H0: ajuste compatible con los datos.")
except Exception as e:
    st.info(f"No se pudo ejecutar KS: {e}")

# Footer
st.markdown("---")
st.markdown("AplicaciÃ³n creada por Orregoâ€‘Ferreyros, LA.")


**************

